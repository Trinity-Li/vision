import torch
import os
import sys
import glob
import csv
import re  # ç”¨äºæå–æ–‡ä»¶åä¸­çš„æ•°å­—


# ==========================================
# 1. æ ¸å¿ƒè®¡ç®—å‡½æ•° (è®¡ç®—å…¨å±€ä½“ç§¯)
# ==========================================
def calculate_global_volume(features):
    """
    è®¡ç®—ç‰¹å¾çŸ©é˜µçš„æ„ŸçŸ¥æµå½¢ä½“ç§¯ã€‚
    features: (512, m) çš„å¼ é‡
    """
    if features.dtype != torch.float32 and features.dtype != torch.float64:
        features = features.float()

    p, m = features.shape
    if m <= 1: return 0.0

    # æ ‡å‡†è®¡ç®—æ­¥éª¤
    z_mean = torch.mean(features, dim=1, keepdim=True)
    z_centered = features - z_mean
    cov_term = torch.mm(z_centered, z_centered.t()) / m
    identity = torch.eye(p, device=features.device)
    sigma_adjusted = identity + cov_term
    log_det_val = torch.logdet(sigma_adjusted)
    vol_z = 0.5 * (log_det_val / torch.log(torch.tensor(2.0)))

    return vol_z.item()


# ==========================================
# 2. è¾…åŠ©å‡½æ•°ï¼šåŠ è½½æ•°æ®ä¸æå–ç‰¹å¾
# ==========================================
def load_features_from_file(file_path):
    """å…¼å®¹ List[Dict] å’Œ Dict[Tensor] ä¸¤ç§æ ¼å¼"""
    try:
        data = torch.load(file_path, map_location='cpu')
    except Exception as e:
        print(f"  âŒ æ–‡ä»¶æŸå: {e}")
        return None

    # æ ¼å¼ A: ç´§å‡‘æ ¼å¼ (Dict)
    if isinstance(data, dict) and 'features' in data:
        return data['features']  # (N, 512)

    # æ ¼å¼ B: æ¾æ•£æ ¼å¼ (List)
    elif isinstance(data, list):
        # æå– feature å­—æ®µå¹¶å †å 
        feat_list = [item['feature'] for item in data if 'feature' in item]
        if feat_list:
            return torch.stack(feat_list)

    return None


# ==========================================
# 3. ä¸»ç¨‹åº
# ==========================================
if __name__ == "__main__":
    # --- é…ç½® ---
    # 1. åŸå§‹æ–‡ä»¶è·¯å¾„ (è¯·ä¿®æ”¹ä¸ºä½ å®é™…çš„åŸå§‹æ–‡ä»¶è·¯å¾„)
    ORIGINAL_FILE = 'autodl-tmp/eval/references/classification/eval_set_B_features.pt'

    # 2. æ‰°åŠ¨æ–‡ä»¶æœç´¢æ¨¡å¼
    PERTURBED_PATTERN = 'eval_set_B_perturbed_*.pt'

    # 3. è¾“å‡ºç»“æœæ–‡ä»¶
    OUTPUT_CSV = 'global_volume_comparison.csv'

    # --- æœé›†æ‰€æœ‰æ–‡ä»¶ ---
    tasks = []

    # 1. æ·»åŠ åŸå§‹æ–‡ä»¶ (å¦‚æœå­˜åœ¨)
    if os.path.exists(ORIGINAL_FILE):
        tasks.append({
            'path': ORIGINAL_FILE,
            'type': 'Original',
            'ratio': 0.0  # åŸå§‹æ•°æ®åˆ é™¤ç‡ä¸º 0%
        })
    else:
        # å°è¯•åœ¨å½“å‰ç›®å½•æ‰¾
        base_name = os.path.basename(ORIGINAL_FILE)
        if os.path.exists(base_name):
            tasks.append({'path': base_name, 'type': 'Original', 'ratio': 0.0})
        else:
            print(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°åŸå§‹æ–‡ä»¶ {ORIGINAL_FILE}")

    # 2. æ·»åŠ æ‰°åŠ¨æ–‡ä»¶
    perturbed_files = glob.glob(PERTURBED_PATTERN)
    for p_file in perturbed_files:
        # ä»æ–‡ä»¶åä¸­æå–æ¯”ä¾‹ (ä¾‹å¦‚ ..._0.2.pt -> 0.2)
        # ä½¿ç”¨æ­£åˆ™å¯»æ‰¾ 0.x çš„æ•°å­—
        match = re.search(r'_(\d+\.\d+)\.pt', p_file)
        ratio = float(match.group(1)) if match else -1.0

        tasks.append({
            'path': p_file,
            'type': 'Perturbed',
            'ratio': ratio
        })

    # 3. æŒ‰æ¯”ä¾‹æ’åº (0.0 -> 0.1 -> 0.2 ...)
    tasks.sort(key=lambda x: x['ratio'])

    print(f"ğŸ“‹ æ‰¾åˆ° {len(tasks)} ä¸ªæ–‡ä»¶ä»»åŠ¡ï¼Œå‡†å¤‡å¼€å§‹...\n")
    print(f"{'Type':<10} {'Ratio':<8} {'Samples':<10} {'Global Volume':<15}")
    print("-" * 50)

    results = []

    # --- å¾ªç¯å¤„ç† ---
    for task in tasks:
        file_path = task['path']
        ratio = task['ratio']
        dtype = task['type']

        # 1. åŠ è½½ç‰¹å¾
        features = load_features_from_file(file_path)

        if features is None:
            continue

        n_samples = features.shape[0]

        # 2. æ ¸å¿ƒï¼šè½¬ç½®å¹¶è®¡ç®—
        # features æ˜¯ (N, 512)ï¼Œè®¡ç®—éœ€è¦ (512, N)
        z_input = features.t()

        vol = calculate_global_volume(z_input)

        # 3. æ‰“å°ä¸è®°å½•
        print(f"{dtype:<10} {ratio:<8} {n_samples:<10} {vol:.4f}")

        results.append([dtype, ratio, n_samples, f"{vol:.6f}", os.path.basename(file_path)])

    # --- ä¿å­˜ CSV ---
    print("-" * 50)
    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜å¯¹æ¯”æŠ¥å‘Šåˆ° {OUTPUT_CSV} ...")

    with open(OUTPUT_CSV, mode='w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['Type', 'Deletion Ratio', 'Sample Count', 'Global Volume', 'Filename'])
        writer.writerows(results)

    print("âœ… å®Œæˆï¼")