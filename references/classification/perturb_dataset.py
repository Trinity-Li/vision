import torch
import random
import copy
import os
import sys


# ==========================================
# 1. æ ¸å¿ƒå¤„ç†å‡½æ•° (ä¿æŒä¸å˜)
# ==========================================
def perturb_dataset(data, drop_ratio=0.1):
    """
    å¯¹æ•°æ®é›†è¿›è¡Œæ‰°åŠ¨ï¼š
    1. æŒ‰ç±»åˆ«éšæœºåˆ é™¤ drop_ratio æ¯”ä¾‹çš„æ ·æœ¬ã€‚
    2. åœ¨è¯¥ç±»å‰©ä½™æ ·æœ¬ä¸­éšæœºé€‰ä¸€å¼ ï¼Œå¤åˆ¶å¹¶å¡«è¡¥åˆ é™¤çš„ç©ºç¼ºã€‚
    """
    print(f"\nâš¡ [å¤„ç†ä¸­] ç›®æ ‡åˆ é™¤æ¯”ä¾‹: {drop_ratio * 100:.0f}%")

    # 1. æŒ‰ç±»åˆ«åˆ†ç»„
    class_buckets = {}
    for item in data:
        label = item['label']
        if label not in class_buckets:
            class_buckets[label] = []
        class_buckets[label].append(item)

    final_data = []

    # 2. éå†æ¯ä¸ªç±»åˆ«
    for label in sorted(class_buckets.keys()):
        items = class_buckets[label]
        original_count = len(items)

        # è®¡ç®—æ•°é‡
        n_drop = int(original_count * drop_ratio)
        n_keep = original_count - n_drop

        if n_keep < 1:
            # æå°‘æ•°æƒ…å†µï¼šå¦‚æœæ¯”ä¾‹å¤ªé«˜å¯¼è‡´ä¸€å¼ ä¸å‰©ï¼Œå¼ºåˆ¶ä¿ç•™ä¸€å¼ ç”¨äºå¤åˆ¶
            n_keep = 1
            n_drop = original_count - 1
            print(f"  ! è­¦å‘Š: ç±»åˆ« {label} æ ·æœ¬è¿‡å°‘ï¼Œå¼ºåˆ¶ä¿ç•™1å¼ ã€‚")

        # A. éšæœºæ‰“ä¹±å¹¶æˆªå–
        random.shuffle(items)
        kept_items = items[:n_keep]

        # B. é€‰ç§å­
        seed_item = random.choice(kept_items)

        # C. å¤åˆ¶å¡«è¡¥
        duplicates = []
        for i in range(n_drop):
            dup = copy.deepcopy(seed_item)
            # ä¿®æ”¹ ID ä»¥ç¤ºåŒºåˆ†
            if 'id' in dup and isinstance(dup['id'], str):
                base_id = os.path.splitext(dup['id'])[0]
                ext = os.path.splitext(dup['id'])[1]
                dup['id'] = f"{base_id}_r{drop_ratio}_copy{i}{ext}"
            duplicates.append(dup)

        # åˆå¹¶
        new_class_list = kept_items + duplicates
        assert len(new_class_list) == original_count
        final_data.extend(new_class_list)

    return final_data


# ==========================================
# 2. ä¸»ç¨‹åº (ä¿®æ”¹æ”¯æŒæ‰¹é‡ä¿å­˜)
# ==========================================
if __name__ == "__main__":
    # --- é…ç½®åŒºåŸŸ ---
    input_path = 'autodl-tmp/eval/references/classification/eval_set_B_features.pt'

    # åœ¨è¿™é‡Œå®šä¹‰ä½ æƒ³è¦ç”Ÿæˆçš„æ¯”ä¾‹åˆ—è¡¨ (0.1 ä»£è¡¨ 10%, 0.5 ä»£è¡¨ 50%)
    RATIOS_TO_GENERATE = [0.2, 0.4, 0.6, 0.8, 1.0]

    # è¾“å‡ºæ–‡ä»¶åçš„å‰ç¼€
    output_prefix = 'eval_set_B_perturbed'

    # --- 1. åŠ è½½æºæ•°æ® (åªåŠ è½½ä¸€æ¬¡) ---
    if not os.path.exists(input_path):
        input_path = os.path.basename(input_path)  # å°è¯•å½“å‰ç›®å½•

    print(f"æ­£åœ¨åŠ è½½æºæ•°æ®: {input_path} ...")
    try:
        source_data = torch.load(input_path, map_location='cpu')
        print(f"âœ… æºæ•°æ®åŠ è½½æˆåŠŸï¼Œå…± {len(source_data)} æ¡æ ·æœ¬ã€‚")
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        sys.exit(1)

    # --- 2. å¾ªç¯ç”Ÿæˆå¹¶ä¿å­˜ ---
    for ratio in RATIOS_TO_GENERATE:
        # ä¸ºäº†ä¸æ±¡æŸ“æºæ•°æ®ï¼Œæ¯æ¬¡å¤„ç†å‰ç¡®ä¿ä½¿ç”¨æ·±æ‹·è´æ˜¯ä¸å¤Ÿçš„ï¼Œ
        # å› ä¸º perturb_dataset å†…éƒ¨å·²ç»åšäº†å¤„ç†ï¼Œ
        # ä½†ä¸ºäº†ä¿é™©èµ·è§ï¼Œæˆ‘ä»¬ä¼ è¿›å»çš„æ•°æ®åˆ—è¡¨æœ¬èº«ä¼šåœ¨å‡½æ•°å†…è¢«åˆ‡ç‰‡è¯»å–ï¼Œ
        # åªè¦ä¸ä¿®æ”¹åŸåˆ—è¡¨é‡Œçš„å¯¹è±¡å¼•ç”¨å³å¯ã€‚
        # ä¸Šé¢çš„ perturb_dataset å®ç°æ˜¯å®‰å…¨çš„ï¼ˆä½¿ç”¨äº† copy.deepcopy ç”Ÿæˆæ–°å…ƒç´ ï¼‰ã€‚

        try:
            # æ‰§è¡Œæ‰°åŠ¨
            new_data = perturb_dataset(source_data, drop_ratio=ratio)

            # æ„é€ å¸¦æ¯”ä¾‹çš„æ–‡ä»¶åï¼Œä¾‹å¦‚: eval_set_B_perturbed_0.2.pt
            save_name = f"{output_prefix}_{ratio}.pt"

            # ä¿å­˜
            print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åˆ°: {save_name} ...")
            torch.save(new_data, save_name)
            print(f"âœ… å®Œæˆæ¯”ä¾‹ {ratio} çš„ç”Ÿæˆã€‚\n")

        except Exception as e:
            print(f"âŒ å¤„ç†æ¯”ä¾‹ {ratio} æ—¶å‡ºé”™: {e}")
            continue

    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼")